{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":12669338,"sourceType":"datasetVersion","datasetId":8006273}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"! pip install sastrawi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:31.217908Z","iopub.execute_input":"2025-08-04T12:13:31.218405Z","iopub.status.idle":"2025-08-04T12:13:35.495857Z","shell.execute_reply.started":"2025-08-04T12:13:31.218379Z","shell.execute_reply":"2025-08-04T12:13:35.495076Z"}},"outputs":[{"name":"stdout","text":"Collecting sastrawi\n  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\nDownloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: sastrawi\nSuccessfully installed sastrawi-1.0.1\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nfrom Sastrawi.Stemmer.StemmerFactory import StemmerFactory\nfrom Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:35.497500Z","iopub.execute_input":"2025-08-04T12:13:35.497730Z","iopub.status.idle":"2025-08-04T12:13:35.521950Z","shell.execute_reply.started":"2025-08-04T12:13:35.497706Z","shell.execute_reply":"2025-08-04T12:13:35.521176Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Download necessary NLTK resources\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('omw-1.4')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:35.522615Z","iopub.execute_input":"2025-08-04T12:13:35.522795Z","iopub.status.idle":"2025-08-04T12:13:35.887975Z","shell.execute_reply.started":"2025-08-04T12:13:35.522779Z","shell.execute_reply":"2025-08-04T12:13:35.887332Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/portfolio-nlp-for-bdc-satriadata/dataset_penyisihan_bdc_2024.csv\", delimiter=\";\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:35.889333Z","iopub.execute_input":"2025-08-04T12:13:35.889541Z","iopub.status.idle":"2025-08-04T12:13:35.945633Z","shell.execute_reply.started":"2025-08-04T12:13:35.889524Z","shell.execute_reply":"2025-08-04T12:13:35.944758Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:35.946472Z","iopub.execute_input":"2025-08-04T12:13:35.946770Z","iopub.status.idle":"2025-08-04T12:13:35.972223Z","shell.execute_reply.started":"2025-08-04T12:13:35.946744Z","shell.execute_reply":"2025-08-04T12:13:35.971434Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 5000 entries, 0 to 4999\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   text    5000 non-null   object\n 1   label   5000 non-null   object\ndtypes: object(2)\nmemory usage: 78.3+ KB\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:35.973006Z","iopub.execute_input":"2025-08-04T12:13:35.973305Z","iopub.status.idle":"2025-08-04T12:13:35.996579Z","shell.execute_reply.started":"2025-08-04T12:13:35.973279Z","shell.execute_reply":"2025-08-04T12:13:35.995884Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                text             label\n0  Kunjungan Prabowo ini untuk meresmikan dan men...  Sumber Daya Alam\n1  RT Anies dapat tepuk tangan meriah saat jadi R...           Politik\n2  @CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...         Demografi\n3  RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...           Politik\n4  Anies Baswedan Harap ASN termasuk TNI dan Polr...           Politik","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Kunjungan Prabowo ini untuk meresmikan dan men...</td>\n      <td>Sumber Daya Alam</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>RT Anies dapat tepuk tangan meriah saat jadi R...</td>\n      <td>Politik</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>@CIqXqwGAT04tMtx4OCATxjoVq7vv/Y8HeYaIOgMFg8Y= ...</td>\n      <td>Demografi</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>RT @L3R8XFBw3WGbxRPSj0/0hHZTbqVGX7qtfwRg9zmhK7...</td>\n      <td>Politik</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Anies Baswedan Harap ASN termasuk TNI dan Polr...</td>\n      <td>Politik</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"print(data['label'].unique())\nprint(data.label.value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:35.997299Z","iopub.execute_input":"2025-08-04T12:13:35.997547Z","iopub.status.idle":"2025-08-04T12:13:36.003242Z","shell.execute_reply.started":"2025-08-04T12:13:35.997524Z","shell.execute_reply":"2025-08-04T12:13:36.002603Z"}},"outputs":[{"name":"stdout","text":"['Sumber Daya Alam' 'Politik' 'Demografi' 'Pertahanan dan Keamanan'\n 'Ideologi' 'Ekonomi' 'Sosial Budaya' 'Geografi']\nlabel\nPolitik                    2972\nSosial Budaya               587\nIdeologi                    400\nPertahanan dan Keamanan     400\nEkonomi                     367\nSumber Daya Alam            192\nDemografi                    62\nGeografi                     20\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"### Stopword dan Lematisasi","metadata":{}},{"cell_type":"code","source":"# Initialize Sastrawi Stemmer and Stopword Remover\nstemmer = StemmerFactory().create_stemmer()\nstopwords = set(StopWordRemoverFactory().get_stop_words())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:36.531068Z","iopub.execute_input":"2025-08-04T12:13:36.531327Z","iopub.status.idle":"2025-08-04T12:13:36.542589Z","shell.execute_reply.started":"2025-08-04T12:13:36.531310Z","shell.execute_reply":"2025-08-04T12:13:36.541924Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"### Cleaning","metadata":{}},{"cell_type":"code","source":"# Text Cleaning Function\ndef clean_text(text):\n    text = text.lower()  # lowercase\n    text = re.sub(r'http\\S+', '', text)  # hapus URL\n    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # hapus karakter non-alfanumerik\n    text = re.sub(r'\\s+', ' ', text).strip()  # hapus spasi berlebih\n    words = text.split()  # tokenisasi manual\n    # hapus stopword dan stemming\n    words = [stemmer.stem(word) for word in words if word not in stopwords]\n    return ' '.join(words)\n\ndata['clean_text'] = data['text'].apply(clean_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-04T12:13:37.484719Z","iopub.execute_input":"2025-08-04T12:13:37.485464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Padding dan Tokenisasi","metadata":{}},{"cell_type":"code","source":"# Tokenization and Padding\nMAX_WORDS = 10000  # Vocabulary size\nMAX_LEN = 100  # Max length of sequences\ntokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(data['clean_text'])\n\nsequences = tokenizer.texts_to_sequences(data['clean_text'])\npadded_sequences = pad_sequences(sequences, maxlen=MAX_LEN, padding='post', truncating='post')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}