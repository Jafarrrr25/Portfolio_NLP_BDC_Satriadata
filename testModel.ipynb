{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59c7c42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import string\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b0d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/dataset_unlabeled_penyisihan_bdc_2024.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28a74de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   IDText  1000 non-null   object\n",
      " 1   Text    1000 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48dfed89",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fungsi membersihkan teks tanpa stemming/lemmatisasi\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # 1. Hapus RT, via, cc di awal\n",
    "    text = re.sub(r'^(RT|rt|via|cc)\\b', '', text).strip()\n",
    "\n",
    "    # 2. Hapus mention @username\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "\n",
    "    # 3. Hapus URL\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "\n",
    "    # 4. Hapus hashtag\n",
    "    text = re.sub(r'#\\S+', '', text)\n",
    "\n",
    "    # 5. Hapus bracket [RE ...] atau yang sejenis\n",
    "    text = re.sub(r'\\[.*?\\]', '', text)\n",
    "\n",
    "    # 6. Hapus encoding random (+ECNv...= dsb)\n",
    "    text = re.sub(r'\\S*=\\S*', '', text)\n",
    "\n",
    "    # 7. Hapus karakter non-ASCII dan simbol aneh\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    # 8. Normalisasi unicode (hilangkan diakritik tak perlu)\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # 9. Hapus tanda baca\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "\n",
    "    # 10. Ganti & menjadi \"dan\"\n",
    "    text = text.replace(\"&\", \" dan \")\n",
    "\n",
    "    # 11. Hapus spasi berlebih\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "# Terapkan ke kolom data\n",
    "data['clean_text'] = data['Text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0716172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus baris jika kolom 'clean_text' kosong atau hanya berisi spasi\n",
    "data = data[data['clean_text'].astype(str).str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da2765b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "factory = StemmerFactory()\n",
    "stemmer = factory.create_stemmer()\n",
    "\n",
    "def stem_text(text):\n",
    "    return stemmer.stem(text)\n",
    "\n",
    "# 2. Terapkan stemming\n",
    "data['stemmed_text'] = data['clean_text'].apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6dc23a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDText</th>\n",
       "      <th>Text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>stemmed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXT0001</td>\n",
       "      <td>Lu mau org2 pro-demokrasi di negara ini bisa p...</td>\n",
       "      <td>lu mau org2 prodemokrasi di negara ini bisa pu...</td>\n",
       "      <td>lu mau org2 prodemokrasi di negara ini bisa pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXT0002</td>\n",
       "      <td>Prabowo ditanya soal hutang luar negeri dia me...</td>\n",
       "      <td>prabowo ditanya soal hutang luar negeri dia me...</td>\n",
       "      <td>prabowo tanya soal hutang luar negeri dia jawa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXT0003</td>\n",
       "      <td>kiki_daliyo  Ganjar Pranowo itulah beliau soso...</td>\n",
       "      <td>kikidaliyo ganjar pranowo itulah beliau sosok ...</td>\n",
       "      <td>kikidaliyo ganjar pranowo itu beliau sosok yan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXT0004</td>\n",
       "      <td>@kumparan Prabowo Gibran yang bisa melakukan i...</td>\n",
       "      <td>prabowo gibran yang bisa melakukan itu semua d...</td>\n",
       "      <td>prabowo gibran yang bisa laku itu semua demi s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXT0005</td>\n",
       "      <td>@sniperruben45 @uda_zulhendra @ainunnajib Lah ...</td>\n",
       "      <td>lah justru yg gak nyambung junjungan elu aomkm...</td>\n",
       "      <td>lah justru yg gak nyambung junjung elu aomkmkm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IDText                                               Text  \\\n",
       "0  TXT0001  Lu mau org2 pro-demokrasi di negara ini bisa p...   \n",
       "1  TXT0002  Prabowo ditanya soal hutang luar negeri dia me...   \n",
       "2  TXT0003  kiki_daliyo  Ganjar Pranowo itulah beliau soso...   \n",
       "3  TXT0004  @kumparan Prabowo Gibran yang bisa melakukan i...   \n",
       "4  TXT0005  @sniperruben45 @uda_zulhendra @ainunnajib Lah ...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  lu mau org2 prodemokrasi di negara ini bisa pu...   \n",
       "1  prabowo ditanya soal hutang luar negeri dia me...   \n",
       "2  kikidaliyo ganjar pranowo itulah beliau sosok ...   \n",
       "3  prabowo gibran yang bisa melakukan itu semua d...   \n",
       "4  lah justru yg gak nyambung junjungan elu aomkm...   \n",
       "\n",
       "                                        stemmed_text  \n",
       "0  lu mau org2 prodemokrasi di negara ini bisa pu...  \n",
       "1  prabowo tanya soal hutang luar negeri dia jawa...  \n",
       "2  kikidaliyo ganjar pranowo itu beliau sosok yan...  \n",
       "3  prabowo gibran yang bisa laku itu semua demi s...  \n",
       "4  lah justru yg gak nyambung junjung elu aomkmkm...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37cacda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/testData.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37f7ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tes_data = pd.read_csv(\"data/testData.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf7f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load vectorizer yang sudah di-fit\n",
    "vectorizer = joblib.load(\"tfidf_vectorizer.pkl\")\n",
    "\n",
    "# Transform data test\n",
    "X_test_new = vectorizer.transform(tes_data['stemmed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b7c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model= joblib.load(\"xgb_model.pkl\")\n",
    "lgb_model = joblib.load(\"lgb_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c4d3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== XGBOOST ===\n",
      "=== Average Confidence per Class ===\n",
      "predicted_label\n",
      "Demografi                  0.616803\n",
      "Ekonomi                    0.863528\n",
      "Geografi                   0.784952\n",
      "Ideologi                   0.534091\n",
      "Pertahanan dan Keamanan    0.678387\n",
      "Politik                    0.739568\n",
      "Sosial Budaya              0.513265\n",
      "Sumber Daya Alam           0.535077\n",
      "Name: confidence, dtype: float32\n",
      "\n",
      "=== Overall Average Confidence ===\n",
      "0.7235\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "le = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "print(\"=== XGBOOST ===\")\n",
    "\n",
    "# Probabilitas prediksi\n",
    "probs = xgb_model.predict_proba(X_test_new)\n",
    "\n",
    "# Prediksi label\n",
    "predictions = xgb_model.predict(X_test_new)\n",
    "predicted_labels = le.inverse_transform(predictions)\n",
    "\n",
    "# Confidence tertinggi tiap sampel\n",
    "confidence_scores = probs.max(axis=1)\n",
    "\n",
    "# Tambahkan ke DataFrame sementara\n",
    "test_pred_df = pd.DataFrame({\n",
    "    \"predicted_label\": predicted_labels,\n",
    "    \"confidence\": confidence_scores\n",
    "})\n",
    "\n",
    "# Rata-rata confidence per kelas\n",
    "avg_conf_per_class = test_pred_df.groupby(\"predicted_label\")[\"confidence\"].mean()\n",
    "\n",
    "# Rata-rata keseluruhan\n",
    "avg_conf_overall = confidence_scores.mean()\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(\"=== Average Confidence per Class ===\")\n",
    "print(avg_conf_per_class)\n",
    "print(\"\\n=== Overall Average Confidence ===\")\n",
    "print(round(avg_conf_overall, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fdd3992b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LGBM ===\n",
      "=== Average Confidence per Class ===\n",
      "predicted_label\n",
      "Demografi                  0.674272\n",
      "Ekonomi                    0.880885\n",
      "Geografi                   0.900583\n",
      "Ideologi                   0.607178\n",
      "Pertahanan dan Keamanan    0.736355\n",
      "Politik                    0.811460\n",
      "Sosial Budaya              0.615820\n",
      "Sumber Daya Alam           0.636672\n",
      "Name: confidence, dtype: float64\n",
      "\n",
      "=== Overall Average Confidence ===\n",
      "0.7908\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "le = joblib.load(\"label_encoder.pkl\")\n",
    "\n",
    "print(\"=== LGBM ===\")\n",
    "\n",
    "# Probabilitas prediksi\n",
    "probs_lgb = lgb_model.predict_proba(X_test_new)\n",
    "\n",
    "# Prediksi label\n",
    "predictions_lgb = lgb_model.predict(X_test_new)\n",
    "predicted_labels_lgb = le.inverse_transform(predictions_lgb)\n",
    "\n",
    "# Confidence tertinggi tiap sampel\n",
    "confidence_scores_lgb = np.max(probs_lgb, axis=1)\n",
    "\n",
    "# DataFrame sementara\n",
    "test_pred_df_lgb = pd.DataFrame({\n",
    "    \"predicted_label\": predicted_labels_lgb,\n",
    "    \"confidence\": confidence_scores_lgb\n",
    "})\n",
    "\n",
    "# Rata-rata confidence per kelas\n",
    "avg_conf_per_class_lgb = test_pred_df_lgb.groupby(\"predicted_label\")[\"confidence\"].mean()\n",
    "\n",
    "# Rata-rata keseluruhan\n",
    "avg_conf_overall_lgb = confidence_scores_lgb.mean()\n",
    "\n",
    "# Tampilkan hasil\n",
    "print(\"=== Average Confidence per Class ===\")\n",
    "print(avg_conf_per_class_lgb)\n",
    "print(\"\\n=== Overall Average Confidence ===\")\n",
    "print(round(avg_conf_overall_lgb, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c401fc77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
